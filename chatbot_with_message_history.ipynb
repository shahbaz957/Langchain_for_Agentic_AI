{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5d3346",
   "metadata": {},
   "source": [
    "# **`Building ChatBot with Message History`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01ae221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # this will import all the api keys in the production environment\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed58c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002159F616FE0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002159F614B20>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\" , groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52551e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Shahbaz, it's nice to meet you! 👋\\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 16, 'total_tokens': 41, 'completion_time': 0.045454545, 'prompt_time': 0.002225719, 'queue_time': 0.292437952, 'total_time': 0.047680264}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--bbe7486d-68f8-4566-92aa-bc39f1a932e6-0', usage_metadata={'input_tokens': 16, 'output_tokens': 25, 'total_tokens': 41})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage \n",
    "model.invoke([HumanMessage(content=\"hi, My name is Shahbaz\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aab28f",
   "metadata": {},
   "source": [
    "## Use of PromptTemplate (which is dynamic part of single message prompt type)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eea2613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are greetings for Shahbaz in 5 languages:\\n\\n1. **English:** Hello, Shahbaz!\\n2. **Spanish:** Hola, Shahbaz!\\n3. **French:** Bonjour, Shahbaz !\\n4. **German:** Hallo, Shahbaz!\\n5. **Japanese:** こんにちは、シャーバズさん (Konnichiwa, Shābaz-san) \\n\\n\\nLet me know if you'd like greetings in any other languages! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 25, 'total_tokens': 125, 'completion_time': 0.181818182, 'prompt_time': 0.002110179, 'queue_time': 0.261300922, 'total_time': 0.183928361}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ce7065f8-c08d-41f5-aa69-5ed614ecb3a0-0', usage_metadata={'input_tokens': 25, 'output_tokens': 100, 'total_tokens': 125})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "template = PromptTemplate(\n",
    "    template=\"Greet this person in 5 languages. The name of the person is {name}\",\n",
    "    input_variables=['name']\n",
    ")\n",
    "prompt = template.invoke({'name' : 'Shahbaz'})\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d746005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Mirza Shahbaz Baig, it's nice to meet you!\\n\\nThat's a fantastic combination of skills to have - full stack web development and AI engineering.  \\n\\nWhat kind of projects are you working on these days? I'd love to hear more about your work!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 27, 'total_tokens': 89, 'completion_time': 0.112727273, 'prompt_time': 0.002159589, 'queue_time': 0.26103871, 'total_time': 0.114886862}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--2c8aba3b-afbd-41c2-9e96-cf3e18279251-0', usage_metadata={'input_tokens': 27, 'output_tokens': 62, 'total_tokens': 89})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using History Of Messages\n",
    "from langchain_core.messages import HumanMessage , AIMessage\n",
    "model.invoke(\n",
    "    [HumanMessage(content=\"Hi I am Mirza Shahbaz Baig and i am a full Stack Web + AI engineer\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff57efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As a large language model, I don\\'t have memory of past conversations or personal information about individuals.  \\n\\nSo while you told me your name is Mirza Shahbaz Baig and that you are a full-stack web + AI engineer, I don\\'t \"know\" that information in the way a person would. Every interaction we have is a fresh start.  \\n\\nIf you\\'d like to tell me more about yourself or your work, I\\'m happy to listen!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 124, 'total_tokens': 225, 'completion_time': 0.183817184, 'prompt_time': 0.009016388, 'queue_time': 0.519029973, 'total_time': 0.192833572}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b25b5d21-4163-4706-ba5d-b971d3d4a0d4-0', usage_metadata={'input_tokens': 124, 'output_tokens': 101, 'total_tokens': 225})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi I am Mirza Shahbaz Baig and i am a full Stack Web + AI engineer\"),\n",
    "        AIMessage(content=\"That's great, Mirza Shahbaz Baig! \\n\\nIt's impressive to have expertise in both full-stack web development and AI engineering. Those are two rapidly growing fields that are increasingly intertwined. \\n\\nWhat kind of projects are you working on? Are you interested in a particular niche within those areas? I'd love to hear more about your work.\\n\"),\n",
    "        HumanMessage(content=\"Do you Know my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory \n",
    "# class which provide the blueprint that includes the methods and attributes that all chathistories must include it just provide a standard for chatmsghistory which is the actual implementation of history storage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # initialize the message history w.r.t to particular user of particular session id\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model , get_session_history) # Runnable is used for chaining the different components of langchain together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2927e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat1\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5731776",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "       [ HumanMessage(content = \"Hi I am Mirza Shahbaz Baig and i am a full Stack Web + AI engineer\")],\n",
    "        config = config # we are interacting wrt to chat1 session id \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f289d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Mirza Shahbaz Baig.  \\n\\nI remembered it from our first interaction. 😊  Is there anything else I can help you with?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 112, 'total_tokens': 147, 'completion_time': 0.063636364, 'prompt_time': 0.005252799, 'queue_time': 0.26092603600000003, 'total_time': 0.068889163}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a2d15508-b647-4e56-878d-c220783d22dc-0', usage_metadata={'input_tokens': 112, 'output_tokens': 35, 'total_tokens': 147})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "054fefc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 14, 'total_tokens': 57, 'completion_time': 0.078181818, 'prompt_time': 0.001907009, 'queue_time': 0.27247456999999997, 'total_time': 0.080088827}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3a67f240-438d-407e-b95a-d5f8c0d3ead6-0', usage_metadata={'input_tokens': 14, 'output_tokens': 43, 'total_tokens': 57})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Change the config give it different session id\n",
    "config1 = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\" : \"chat12\"\n",
    "    }\n",
    "}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config = config1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8bde1",
   "metadata": {},
   "source": [
    "# **~Working With Prompt Template~**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ab0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate([\n",
    "        ('system' , \"You are an helpfull assistant answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name = \"messages\")\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a8e11cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Mirza Shahbaz Baig! \\n\\nIt's nice to meet you. I'm ready to answer your questions to the best of my ability.  \\n\\nWhat can I help you with today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 34, 'total_tokens': 82, 'completion_time': 0.087272727, 'prompt_time': 0.002304859, 'queue_time': 0.262209422, 'total_time': 0.089577586}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9291700-d441-4765-9053-58db1f503d13-0', usage_metadata={'input_tokens': 34, 'output_tokens': 48, 'total_tokens': 82})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\" : [HumanMessage(content=\"hi my name is Mirza shahbaz Baig\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038410fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain , get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ccda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\" : \"chat3\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534d4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Yes, I do! \\n\\njQuery is a fast, small, and feature-rich JavaScript library. It simplifies many common tasks that developers face when working with JavaScript, making it easier to build interactive and dynamic web pages. \\n\\n**Here are some key things to know about jQuery:**\\n\\n* **DOM Manipulation:** jQuery makes it incredibly easy to select, modify, and create HTML elements. This is essential for building interactive interfaces, animations, and dynamic content updates.\\n* **Event Handling:** jQuery provides a streamlined way to handle user interactions like clicks, hovers, and form submissions.\\n* **Animations:**  jQuery offers a simple syntax for creating smooth and customizable animations, adding visual flair to your websites.\\n* **AJAX:** jQuery simplifies making asynchronous requests to servers, allowing you to fetch data and update content without needing to reload the entire page.\\n* **Cross-browser Compatibility:** jQuery works consistently across different web browsers, making your code more reliable.\\n\\n**Why people love jQuery:**\\n\\n* **Conciseness:** jQuery's syntax is often shorter and more readable than writing plain JavaScript, making code easier to understand and maintain.\\n* **Ease of Use:** jQuery abstracts away much of the complexity of interacting with the browser, making it accessible to developers of all levels.\\n* **Large Community:** jQuery has a vast and active community, meaning there's plenty of support, documentation, and plugins available.\\n\\n**How to learn jQuery:**\\n\\n* **Official Documentation:** The jQuery website ([https://jquery.com/](https://jquery.com/)) has excellent documentation and tutorials.\\n* **Online Courses:**  Many platforms offer comprehensive jQuery courses.\\n* **Practice:** The best way to learn is by building projects and experimenting with jQuery's capabilities.\\n\\n\\nLet me know if you have any more specific questions about jQuery. I'm happy to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 386, 'prompt_tokens': 31, 'total_tokens': 417, 'completion_time': 0.701818182, 'prompt_time': 0.002316769, 'queue_time': 0.266553592, 'total_time': 0.704134951}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--2f469e48-bfa6-4ada-86db-5bbfe7be0391-0', usage_metadata={'input_tokens': 31, 'output_tokens': 386, 'total_tokens': 417})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"do you know about Jquery\")],\n",
    "    config= config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1279f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding More complexity \n",
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate([\n",
    "        ('system' , \"You are an helpfull assistant answer all the question to the best of your ability into {language} language\"),\n",
    "        MessagesPlaceholder(variable_name = \"messages\")\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711a876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola Shahbaz!  \\n\\nEncantado de conocerte.  ¿Cómo puedo ayudarte hoy?  Estoy aquí para responder a todas tus preguntas en español lo mejor que pueda.  \\n\\n¡No dudes en preguntarme lo que necesites! 😄\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 34, 'total_tokens': 89, 'completion_time': 0.1, 'prompt_time': 0.003352397, 'queue_time': 0.258214444, 'total_time': 0.103352397}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--784da676-658d-4096-8aac-cc672856bea4-0', usage_metadata={'input_tokens': 34, 'output_tokens': 55, 'total_tokens': 89})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\"messages\" : [HumanMessage(content=\"Hi My name is Shahbaz\")] , \"language\" : \"Spanish\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebe521",
   "metadata": {},
   "source": [
    "## Manage Conversation History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a48417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage , trim_messages\n",
    "# trim message --> this is reduce function that apply on the message history with the chatbot and reduce the chat messages according to the limit of tokens that is given that helps to manage the context window of an LLM\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True ,# never trim the system message\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    "\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d299fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")|trimmer)\n",
    "    | prompt \n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a130c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\" : messages + [HumanMessage(content=\"What math problem do i ask with you ?\")] , \n",
    "    \"language\" : \"English\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17a49c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can do all sorts of math problems! \\n\\nHere are some ideas:\\n\\n* **Basic arithmetic:** Addition, subtraction, multiplication, division (even with decimals and fractions!)\\n* **Algebra:** Solving for unknowns, simplifying expressions\\n* **Calculus:** Derivatives and integrals (though I'm still learning those!)\\n* **Logic problems:**  I can help you reason through word problems and puzzles.\\n\\nWhat are you in the mood for?\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e24d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
